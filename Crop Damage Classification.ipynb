{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"EimIQgGJnmRS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RtTx0hXqKj-o"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adamhttps://drive.google.com/drive/search?q=owner%3Ame%20(type%3Aapplication%2Fvnd.google.colaboratory%20%7C%7C%20type%3Aapplication%2Fvnd.google.colab)&authuser=0"]},{"cell_type":"code","source":["# Paths to dataset folders\n","TRAIN_DIR = '/content/DATASET/DATASET/TRAIN'\n","TEST_DIR = '/content/DATASET/DATASET/TEST'\n","\n","# Image size and batch size\n","IMG_SIZE = (128, 128)  # Resize all images to 128x128\n","BATCH_SIZE = 32\n","\n","\n","train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n","test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    TRAIN_DIR,\n","    target_size=(128,128),\n","    batch_size=32,\n","    class_mode='binary'   # keep categorical for multiclassification\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    TEST_DIR,\n","    target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary'  #keep categorical for multiclassification\n",")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EcyyioHnWL8l","outputId":"17bf9958-b755-4edb-a8d8-62549f7e41b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 22564 images belonging to 2 classes.\n","Found 2513 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["\n","import zipfile\n","\n","# Replace 'DATASET.zip' with the actual name of your zip file\n","with zipfile.ZipFile('DATASET.zip', 'r') as zip_ref:     # replace it with ur zipfilename\n","    zip_ref.extractall('DATASET') # extracts to a directory called 'DATASET'"],"metadata":{"id":"i4vNNLdIWRen"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_model():\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n","        MaxPooling2D(pool_size=(2, 2)),\n","\n","        Conv2D(64, (3, 3), activation='relu'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","\n","        Conv2D(128, (3, 3), activation='relu'),\n","        MaxPooling2D(pool_size=(2, 2)),\n","\n","        Flatten(),\n","        Dense(128, activation='relu'),\n","        Dropout(0.5),\n","        Dense(1, activation='sigmoid')  # softmax for multi classification\n","    ])\n","\n","    model.compile(optimizer=Adam(),\n","                  loss='binary_crossentropy',  #sparse_categorical_crossentropy for multiclassification\n","                  metrics=['accuracy'])\n","    return model\n","\n","\n","model = build_model()\n","model.summary()\n","\n","#Training the Model\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":504},"id":"5sYLomFHY-lr","outputId":"818b9b8e-7009-41a5-b363-2b4419da48a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,211,392\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,304,769\u001b[0m (12.61 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,769</span> (12.61 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["\n","\n","history = model.fit(\n","    train_generator,\n","    epochs=5,\n","    validation_data=test_generator\n",")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SYd_iS7cZqAV","outputId":"2df53cab-a645-420a-92c3-d50dddc1ab51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 44ms/step - accuracy: 0.7857 - loss: 0.4789 - val_accuracy: 0.8587 - val_loss: 0.3559\n","Epoch 2/5\n","\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 37ms/step - accuracy: 0.8446 - loss: 0.3694 - val_accuracy: 0.8603 - val_loss: 0.3355\n","Epoch 3/5\n","\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 37ms/step - accuracy: 0.8619 - loss: 0.3398 - val_accuracy: 0.8918 - val_loss: 0.2744\n","Epoch 4/5\n","\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 38ms/step - accuracy: 0.8766 - loss: 0.3035 - val_accuracy: 0.9045 - val_loss: 0.2586\n","Epoch 5/5\n","\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 37ms/step - accuracy: 0.8833 - loss: 0.2845 - val_accuracy: 0.9113 - val_loss: 0.2510\n"]}]},{"cell_type":"code","source":["# Saving model\n","model.save('recyclable_vs_organic.h5')   #potato_disease.h5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHadJ1ERaW97","outputId":"2af6136b-142c-49f4-8913-86eb8592ed0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["# 4. Evaluate the Model on Test Data\n","test_loss, test_acc = model.evaluate(test_generator)\n","print(f\"Test Accuracy: {test_acc}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MiqlCp-Oa3tY","outputId":"ff75a36a-a667-4a77-bed7-6d913e74d52a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9204 - loss: 0.2460\n","Test Accuracy: 0.9112614393234253\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Load the trained model\n","model = load_model('/content/recyclable_vs_organic.h5')\n","\n","# Path to your custom image\n","image_path = r\"/content/R_2.jpg\" # Replace with your image path\n","\n","# Preprocess the image\n","IMG_SIZE = (128, 128)  # Must match the size used during training\n","def preprocess_image(image_path):\n","    img = load_img(image_path, target_size=(128,128))  # Load and resize image\n","    img_array = img_to_array(img)  # Convert image to array\n","    img_array = img_array / 255.0  # Rescale to 0-1 range\n","    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","    return img_array\n","\n","image = preprocess_image(image_path)\n","\n","# Make prediction\n","prediction = model.predict(image)\n","print(\"prediction prob\" , prediction)\n","# Interpretation\n","if prediction[0][0] < 0.5:\n","    print(f\"The image is predicted to be Organic:)\")\n","else:\n","    print(f\"The image is predicted to be: Recyclable\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-3iQUYebYgp","outputId":"808aba5a-c14a-49c7-e34d-fa4cd4f096c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step\n","prediction prob [[0.97911984]]\n","The image is predicted to be: Recyclable\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","\n","model = tf.keras.models.load_model('recyclable_vs_organic.h5')\n","\n","def preprocess_image(image):\n","\n","    resized = cv2.resize(image, (128, 128))\n","    normalized = resized / 255.0\n","    return np.expand_dims(normalized, axis=0)  # Add batch dimension\n","\n","def classify_trash(image):\n","\n","    processed = preprocess_image(image)\n","    prediction = model.predict(processed)[0][0]\n","    if prediction[0][0] < 0.5:\n","      return \"Organic\"\n","    else:\n","      return \"Recyclable\"\n","\n","\n","cap = cv2.VideoCapture(1)\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    label = classify_trash(frame)\n","    cv2.putText(frame, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX,\n","                1, (0, 255, 0), 2, cv2.LINE_AA)\n","\n","    cv2.imshow('Trash Classifier', frame)\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"0VXB7t1DpPWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##END OF BINARY CLASSIFICATION USING CNN"],"metadata":{"id":"DyK51JQoc_Vp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"A7kNdn1-c_0u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# below code is for multiclassification prediction do not execute it"],"metadata":{"id":"wXSUUU57enMy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Load the trained model\n","model = load_model('/content/potato_disease.h5')  # Updated model path\n","\n","# Path to your custom image\n","image_path = r\"/content/img.jpg\"  # Replace with your image path\n","\n","# Preprocess the image\n","IMG_SIZE = (128, 128)  # Must match the size used during training\n","\n","def preprocess_image(image_path):\n","    img = load_img(image_path, target_size=IMG_SIZE)  # Load and resize image\n","    img_array = img_to_array(img)  # Convert image to array\n","    img_array = img_array / 255.0  # Rescale to 0-1 range\n","    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","    return img_array\n","\n","image = preprocess_image(image_path)\n","\n","# Make prediction\n","prediction = model.predict(image)\n","\n","# Class labels (ensure they match the model's training)\n","class_labels = ['Early_Blight', 'Healthy', 'Late_Blight']\n","\n","# Get the predicted class index\n","predicted_class_index = np.argmax(prediction, axis=1)[0]\n","predicted_class_label = class_labels[predicted_class_index]\n","\n","# Output the prediction\n","print(f\"The image is predicted to be: {predicted_class_label}\")\n"],"metadata":{"id":"tWfrrn5Qcf7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H66h5lqYnk7d"},"execution_count":null,"outputs":[]}]}